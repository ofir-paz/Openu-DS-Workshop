{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first idea, which was implemented, was to use transfer learning on the existing resnet3d_18 model. By setting the number of deep layers to 2048, we wanted to check if the model could learn each disease pattern regardless of each scan type. After we did some training and validation with different hyperparameters, we noticed that the loss at some point would explode, what was weirder is that the accuracy got stuck around 77%. We concluded that the model wasn't learning the required patterns, and we needed to change it. At this point, we wanted to split the model into a combination of three different classifiers for each scan type, while doing so we also searched for a more fitting architecture for our model. The rest of the training and validation happened inside the Kaggle notebook. While submitting the notebook for scoring, we noticed that while the loss was less than 1 ( and stopped exploding ), it was still unstable and would increase sometime to 1 and above. We tried playing with the model hyperparameters and running the model on the largest amount of epochs that Kaggle allowed us; This didn't change much, which we concluded is the fault of our normalizing and big weights. After adding weight loss and batter normalizing the training accuracy was near 80% and the validation near 75%. We noticed that the model prediction of the 'normal_mild' for each condition was too high, and wanted to add noise for the model to have more samples to train on. After checking different noises, we decided that a Gaussian noise was our best choice - because of the property of an MRI scan. In the end, we didn't have more time to upgrade the model and the model with our Gaussian noise was our last submission. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
